{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b5d48bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b93f719",
   "metadata": {},
   "source": [
    "We're going to analyze a dataset that collects excerpts of text that have been created by Large Language Models (LLMS) and humans. The data is from [Kaggle](https://www.kaggle.com/datasets/starblasters8/human-vs-llm-text-corpus), but it has been preprocessed somewhat:\n",
    "- Only 10% of the data is present (uniformly randomly sampled)\n",
    "- The text fields have been `strip`ped from leading and ending whitespace\n",
    "- The irrelevant columns have been removed.\n",
    "\n",
    "The idea is to try to detect if the text was generated by an LLM. Let's explore the data a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "560eb0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('human_vs_llm.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a624aff",
   "metadata": {},
   "source": [
    "Note that Pandas can natively also read compressed data. Let's look at the shape of the data and the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebec83ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78282, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9528b30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'source'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10c487fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LLM', 'Human'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742aca73",
   "metadata": {},
   "source": [
    "So the `source` column should act as our class label: it identifies the LLM used, or alternatively that the text came from a human being. We also have a worrying `Unknown` label that we should probably get rid of. Let's see the relative frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7bc84ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44653943435272475"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['source'] == 'Human').sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee36c20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5534605656472752"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(~(df['source'].isin(['Human','Unknown']))).sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7744e5",
   "metadata": {},
   "source": [
    "The dataset appears ok, it's almost a 50:50 split, so neither class is very badly overrepresented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc14c350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Mongol Empire was governed by a civilian a...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tito woke up with a headache. He called in sic...</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Holt  \\nThanks for taking time to give me so ...</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The appendix does have use. It has a role in m...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A giant panda in Hong Kong called Ying Ying is...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78277</th>\n",
       "      <td>Fire Protection in Commercial and Industrial B...</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78278</th>\n",
       "      <td>Restaurants aren't required to list ingredient...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78279</th>\n",
       "      <td>In the United States, their persistent legal c...</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78280</th>\n",
       "      <td>They will pay you a percentage for your time, ...</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78281</th>\n",
       "      <td>Jack Ma has been absent from public view for t...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78282 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text source\n",
       "0      The Mongol Empire was governed by a civilian a...    LLM\n",
       "1      Tito woke up with a headache. He called in sic...  Human\n",
       "2      @Holt  \\nThanks for taking time to give me so ...  Human\n",
       "3      The appendix does have use. It has a role in m...    LLM\n",
       "4      A giant panda in Hong Kong called Ying Ying is...    LLM\n",
       "...                                                  ...    ...\n",
       "78277  Fire Protection in Commercial and Industrial B...  Human\n",
       "78278  Restaurants aren't required to list ingredient...    LLM\n",
       "78279  In the United States, their persistent legal c...  Human\n",
       "78280  They will pay you a percentage for your time, ...  Human\n",
       "78281  Jack Ma has been absent from public view for t...    LLM\n",
       "\n",
       "[78282 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e44aefbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "LLM      43326\n",
       "Human    34956\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b396d0",
   "metadata": {},
   "source": [
    "Let's perform a train-test split. By default this is done at a 3:1 ratio, which works well for us. Rows are selected randomly.\n",
    "\n",
    "It is good practice to always explicitly define the seed so that we can repeat the experiments later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08c2ba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "df_train, df_test = train_test_split(df,random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eec441ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33966</th>\n",
       "      <td>The colour of the sky is caused by sunlight li...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31900</th>\n",
       "      <td>The availability of the Bible in vernacular la...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48861</th>\n",
       "      <td>Front Line Employees and Service Quality Cours...</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27757</th>\n",
       "      <td>We study the power and limits of optimal dynam...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50355</th>\n",
       "      <td>sorry to say I did not have a good experience ...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55985</th>\n",
       "      <td>***India's grand plan to create world's longes...</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32399</th>\n",
       "      <td>The Face on Mars has long been a topic of fasc...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60620</th>\n",
       "      <td>This is a very sensitive topic so sorry for po...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34086</th>\n",
       "      <td>The American Way of Dining Out Research Paper\\...</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58067</th>\n",
       "      <td>The Ethics of Animal-Assisted Interventions in...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58711 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text source\n",
       "33966  The colour of the sky is caused by sunlight li...    LLM\n",
       "31900  The availability of the Bible in vernacular la...    LLM\n",
       "48861  Front Line Employees and Service Quality Cours...  Human\n",
       "27757  We study the power and limits of optimal dynam...    LLM\n",
       "50355  sorry to say I did not have a good experience ...    LLM\n",
       "...                                                  ...    ...\n",
       "55985  ***India's grand plan to create world's longes...  Human\n",
       "32399  The Face on Mars has long been a topic of fasc...    LLM\n",
       "60620  This is a very sensitive topic so sorry for po...    LLM\n",
       "34086  The American Way of Dining Out Research Paper\\...  Human\n",
       "58067  The Ethics of Animal-Assisted Interventions in...    LLM\n",
       "\n",
       "[58711 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dc8fa7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44700</th>\n",
       "      <td>SORRY ABOUT ALL THE ERRORS A BETTER COPY WILL ...</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65161</th>\n",
       "      <td>Like other posts...you get what you pay for......</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45938</th>\n",
       "      <td>Counter-argument: The problem with cultural ap...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37709</th>\n",
       "      <td>Internet of Things (IoT) is the next big evolu...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4847</th>\n",
       "      <td>Learning new skills is an essential part of pe...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77824</th>\n",
       "      <td>is smiling and waving The camera pans around t...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60419</th>\n",
       "      <td>Inventory systems are generally software produ...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66993</th>\n",
       "      <td>Kate was walking on the sidewalk. She noticed ...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15468</th>\n",
       "      <td>Venus, also known as the Earth's sister planet...</td>\n",
       "      <td>LLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27118</th>\n",
       "      <td>You have a lot of nervesnerve endings going to...</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19571 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text source\n",
       "44700  SORRY ABOUT ALL THE ERRORS A BETTER COPY WILL ...  Human\n",
       "65161  Like other posts...you get what you pay for......    LLM\n",
       "45938  Counter-argument: The problem with cultural ap...    LLM\n",
       "37709  Internet of Things (IoT) is the next big evolu...    LLM\n",
       "4847   Learning new skills is an essential part of pe...    LLM\n",
       "...                                                  ...    ...\n",
       "77824  is smiling and waving The camera pans around t...    LLM\n",
       "60419  Inventory systems are generally software produ...    LLM\n",
       "66993  Kate was walking on the sidewalk. She noticed ...    LLM\n",
       "15468  Venus, also known as the Earth's sister planet...    LLM\n",
       "27118  You have a lot of nervesnerve endings going to...  Human\n",
       "\n",
       "[19571 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45b3e9f",
   "metadata": {},
   "source": [
    "In order for our model to make *any* sense, we must be able to beat the dummy classifier. Let us determine the most common class and see the accuracy if we predicted every value was from this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c13d5d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "LLM      32444\n",
       "Human    26267\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['source'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8ec6a8",
   "metadata": {},
   "source": [
    "So the dummy classifier should predict that all values are LLMs. Let's see the accuracy we can achieve with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bd0d5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5560267743089264"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_dummy = (df_test['source'] == 'LLM').sum()/df_test.shape[0]\n",
    "acc_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ed155f",
   "metadata": {},
   "source": [
    "As the data is almost 50:50, the dummy classifier is little better than tossing a coin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cbb017",
   "metadata": {},
   "source": [
    "Then we'll preprocess the data into bags of words using the `CountVectorizer` from scikit learn.\n",
    "\n",
    "The function `fit_transform` does two things: it fits the data (assigns numerical values to words, that is, indices in the vector), and applies the transformation to the dataset in question. This corresponds to doing first `fit` and then `transform`.\n",
    "\n",
    "The function `transform` can only be applied after `fit` has been called: it will then map the known words to their indices and count them; unknown words (that were not encountered during `fit`) are ignored. This is appropriate for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3208fc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<58711x186107 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 12200852 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "X_train = cv.fit_transform(df_train['text'])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6ebdc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<19571x186107 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4016942 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = cv.transform(df_test['text'])\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fd745f",
   "metadata": {},
   "source": [
    "We will then convert the class labels, given as strings, into (arbitrarily ordered) numerical classes using the label encoder. This is appropriate because the classifiers tend to assume numerical class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0eb0931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df_train['source'])\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96d9eade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = le.transform(df_test['source'])\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab80a260",
   "metadata": {},
   "source": [
    "We will start by contructing a Bernoulli Naive Bayes classifier. The interface for all classifiers is relatively uniform in sklearn. We first `fit` the data which constructs the model. The arguments are `X` and `y`: observations (observations by the row, features by the column) as a matrix `X`, and the associated class labels as a vector `y`.\n",
    "\n",
    "The data is precisely in this format: which we can check (the number of rows in `X` must match the length of `y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52b1c2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((58711, 186107), (58711,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f731169c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bace21",
   "metadata": {},
   "source": [
    "We can then `predict` the class labels of our test observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1bf315b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_bnb = bnb.predict(X_test)\n",
    "y_pred_bnb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be38b850",
   "metadata": {},
   "source": [
    "Accuracy simply tells the fraction of observations that match the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1314de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7103878187113587"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_bnb = (y_test == y_pred_bnb).sum()/y_test.shape[0]\n",
    "acc_bnb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a525164f",
   "metadata": {},
   "source": [
    "This is significantly better than tossing a coin, but not very reliable. Let's see if we can improve this by using a Multinomial Naive Bayes classifier. It works exactly the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8916b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7352204792805682"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train,y_train)\n",
    "y_pred_mnb = mnb.predict(X_test)\n",
    "acc_mnb = (y_test == y_pred_mnb).sum()/y_test.shape[0]\n",
    "acc_mnb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d295664",
   "metadata": {},
   "source": [
    "Slightly better! Let's have a more nouanced view about the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15780a0",
   "metadata": {},
   "source": [
    "We say that a *positive* case is such that the text was produced by LLM, as this is consistent with the idea of \"detecting LLM use\".\n",
    "\n",
    "We will then compute the true/false positives/negatives and then precision and recall which are standard measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0d79ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7352204792805682, 0.7207933064766037, 0.8549898915640507)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_inv = le.inverse_transform(y_test)\n",
    "y_pred_mnb_inv = le.inverse_transform(y_pred_mnb)\n",
    "tp = ((y_test_inv == 'LLM') & (y_pred_mnb_inv == 'LLM')).sum()\n",
    "fp = ((y_test_inv == 'Human') & (y_pred_mnb_inv == 'LLM')).sum()\n",
    "fn = ((y_test_inv == 'LLM') & (y_pred_mnb_inv == 'Human')).sum()\n",
    "tn = ((y_test_inv == 'Human') & (y_pred_mnb_inv == 'Human')).sum()\n",
    "acc = (tp+tn)/(tp+fp+tn+fn)\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "acc, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905c8f85",
   "metadata": {},
   "source": [
    "This suggests that we are reliable in recovering observations that were generated by an LLM but the precision is lower, so we get too many observations labelled as LLMs. Let's have a look at the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b37a23ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9304, 1578],\n",
       "       [3604, 5085]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[tp,fn],[fp,tn]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c99df",
   "metadata": {},
   "source": [
    "|                     | **Predicted positive** | **Predicted negative** |\n",
    "|---------------------|------------------------|------------------------|\n",
    "| **Actual positive** | 9304                   | 1578                   |\n",
    "| **Actual negative** | 3604                   | 5085                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7ae8b4",
   "metadata": {},
   "source": [
    "The numbers above were entered manually, so if you run the code again, they might be inconsistent with what you get from NumPy, at least if you are using a different version of the libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbe9d38",
   "metadata": {},
   "source": [
    "This confirms our expectations: the number of false positives is quite high in comparison to false negatives. So our model is trigger happy to label human beings as being AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a400a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
